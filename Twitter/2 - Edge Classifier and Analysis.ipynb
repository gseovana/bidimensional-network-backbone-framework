{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781f66d3-71ef-42e4-baa6-0da4a137347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import rrule\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community  # For Louvain community detection\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import as_completed\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d7aba-02af-40fa-a1b9-b017c1c8ed72",
   "metadata": {},
   "source": [
    "## Retweet Network Backbone Extraction and Edge Classification\n",
    "\n",
    "This notebook cell processes user-user **retweet co-engagement networks** and extracts their **informative backbones** based on two weight dimensions:\n",
    "\n",
    "- **`nij_c`**: the number of times a pair of users retweeted the same tweet (retweet count).\n",
    "- **`nij_t`**: the average temporal proximity (inverted) between users when they co-retweeted the same tweet (retweet time).\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Input**: Edge lists from preprocessed retweet networks located in the `networks/` folder (one file per target date).\n",
    "2. **Backbone Extraction**:\n",
    "   - **Count-based backbone** (`nij_c`) is extracted using the **Polya Urn Filter** as proposed in [ Marcaccioli et al., 2019](https://www.nature.com/articles/s41467-019-08667-3).\n",
    "   - **Time-based backbone** (`nij_t`) is computed after inverting and normalizing the temporal weights, then filtered with the same method.\n",
    "   - ⚠️ **Note**: The actual backbone filtering must be performed externally using the official [MATLAB implementation](https://www.mathworks.com/matlabcentral/fileexchange/69501-pf).\n",
    "3. **Classification**:\n",
    "   - Edges are assigned a class (1–4) based on their statistical significance in each backbone:\n",
    "     - `Class 4`: Significant in both dimensions.\n",
    "     - `Class 2`: Significant only in count.\n",
    "     - `Class 3`: Significant only in time.\n",
    "     - `Class 1`: Not significant in either.\n",
    "\n",
    "### Output\n",
    "\n",
    "For each date, the final classified backbone is saved as: `Backbone-{target_date}.csv` within `networks/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79318359-0bcd-4a6c-9eb3-5ecf55d0bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Define experiment parameters\n",
    "alpha = 0.5                  # Significance level for the Polya filter\n",
    "p_value_threshold_t = 0.05   # p-value threshold for temporal backbone\n",
    "p_value_threshold_c = 0.1    # p-value threshold for count backbone\n",
    "\n",
    "# Dates for which backbones will be extracted\n",
    "target_dates = ['2022-11-01', '2023-01-08']\n",
    "target_dates = [pd.to_datetime(date).date() for date in target_dates]\n",
    "\n",
    "# Function to classify edges based on p-values\n",
    "def classify_edges(row):\n",
    "    if row['p_valor_c'] <= p_value_threshold_c and row['p_valor_t'] <= p_value_threshold_t:\n",
    "        return 4  # Strong in both dimensions\n",
    "    elif row['p_valor_c'] <= p_value_threshold_c:\n",
    "        return 2  # Strong only in retweet count\n",
    "    elif row['p_valor_t'] <= p_value_threshold_t:\n",
    "        return 3  # Strong only in retweet time\n",
    "    else:\n",
    "        return 1  # Weak edge\n",
    "\n",
    "# Iterate over each date to process networks\n",
    "for target_date in target_dates:\n",
    "    print(f\"Processing date: {target_date}\")\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 1. Load the edge list for the given date\n",
    "    # --------------------------------------------\n",
    "    edge_df = pd.read_csv(f\"networks/{target_date}-edges-data.csv\")\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 2. Retweet count backbone (nij_c)\n",
    "    # --------------------------------------------\n",
    "\n",
    "    # NOTE: Replace this block with MATLAB Polya Filter\n",
    "    # The proper backbone extraction must be performed using:\n",
    "    # https://www.mathworks.com/matlabcentral/fileexchange/69501-pf\n",
    "    # from the paper: https://www.nature.com/articles/s41467-019-08667-3\n",
    "\n",
    "    # Simulating a placeholder Polya URN backbone extraction for count\n",
    "    df_count = edge_df[['src', 'trg', 'weight_count']].copy()\n",
    "    df_count.rename(columns={'weight_count': 'nij_c'}, inplace=True)\n",
    "\n",
    "    # Here, insert: MATLAB Polya Filter execution and load result with columns: ['src', 'trg', 'nij_c', 'p_valor_c']\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 3. Temporal backbone (nij_t)\n",
    "    # --------------------------------------------\n",
    "\n",
    "    df_time = edge_df[['src', 'trg', 'weight_time']].copy()\n",
    "    df_time.rename(columns={'weight_time': 'nij_t'}, inplace=True)\n",
    "\n",
    "    # Invert and normalize weights (time proximity -> higher weight)\n",
    "    df_time['nij_t'] = df_time['nij_t'] / 60  # Convert seconds to minutes\n",
    "    max_time = df_time['nij_t'].max()\n",
    "    df_time['nij_t'] = max_time + 1 - df_time['nij_t']  # Invert: closer = stronger\n",
    "    df_time['nij_t'] = np.ceil(df_time['nij_t'])        # Discretize to integers\n",
    "\n",
    "    # Again, insert MATLAB backbone here and load result with ['src', 'trg', 'nij_t', 'p_valor_t']\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 4. Merge both backbone results and classify\n",
    "    # --------------------------------------------\n",
    "\n",
    "    # Simulated backbone merge (in real case, load p-values from MATLAB output)\n",
    "    # df_count must contain ['src', 'trg', 'nij_c', 'p_valor_c']\n",
    "    # df_time must contain  ['src', 'trg', 'nij_t', 'p_valor_t']\n",
    "    merged = pd.merge(df_count, df_time, on=['src', 'trg'])\n",
    "\n",
    "\n",
    "    # Classify edges based on statistical significance in each backbone\n",
    "    merged['edge_class'] = merged.apply(classify_edges, axis=1)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # 5. Save the final result\n",
    "    # --------------------------------------------\n",
    "\n",
    "    output_path = f\"networks/Backbone-{target_date}.csv\"\n",
    "    merged[['src', 'trg', 'nij_c', 'nij_t', 'edge_class']].to_csv(output_path, index=False)\n",
    "    print(f\"Saved classified backbone to: {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ed3e4-ee0e-4d40-b952-6b07ec635bd7",
   "metadata": {},
   "source": [
    "## CDFs\n",
    "\n",
    "\n",
    "This section presents the **Empirical Cumulative Distribution Functions (ECDFs)** of two edge weight dimensions extracted from the retweet co-engagement networks:\n",
    "\n",
    "- **`nij_c`** — Number of times two users co-retweeted the same original tweet (retweet count).\n",
    "- **`nij_t`** — Average time proximity (in minutes) between co-retweets by two users (inverted and normalized).\n",
    "\n",
    "The ECDFs are plotted **separately for each edge class**, as defined by the dual significance in the count-based and time-based backbones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2d10b-7e00-49e9-a4bb-debc27dcae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Reset seaborn to default visual style\n",
    "sns.reset_defaults()\n",
    "\n",
    "# Dates for which plots will be generated\n",
    "target_dates = ['2022-11-01', '2023-01-08']\n",
    "target_dates = [pd.to_datetime(date).date() for date in target_dates]\n",
    "\n",
    "# Ensure output directory for figures exists\n",
    "os.makedirs('figs', exist_ok=True)\n",
    "\n",
    "def plot_ecdf_for_classes(df, variable, save_path, x_axis_label, log_x_axis=False):\n",
    "    \"\"\"\n",
    "    Plot ECDFs for a specific variable grouped by edge class.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data containing the 'edge_class' column and the variable to plot.\n",
    "    - variable (str): Name of the column to plot ('nij_c' or 'nij_t').\n",
    "    - save_path (str): File path to save the resulting plot.\n",
    "    - x_axis_label (str): Label for the x-axis in the plot.\n",
    "    - log_x_axis (bool): Whether to apply a logarithmic scale to the x-axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(4, 3))\n",
    "\n",
    "    # Loop over each edge class and plot its ECDF\n",
    "    for edge_class in sorted(df['edge_class'].unique()):\n",
    "        subset = df[df['edge_class'] == edge_class]\n",
    "        sns.ecdfplot(data=subset, x=variable, label=f'Class {edge_class}')\n",
    "\n",
    "    if log_x_axis:\n",
    "        plt.xscale('log')\n",
    "\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel('P(X ≤ x)')\n",
    "    plt.legend(title='Edge Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------------\n",
    "# Generate ECDF plots for each date\n",
    "# -------------------------------------\n",
    "for target_date in target_dates:\n",
    "    print(f\"Generating ECDF plots for: {target_date}\")\n",
    "\n",
    "    # Load the classified backbone file\n",
    "    df = pd.read_csv(f\"networks/Backbone-{target_date}.csv\")\n",
    "\n",
    "    # Normalize nij_t back to minutes (undo previous inversion logic)\n",
    "    df['nij_t'] = df['nij_t'].astype(int) + 1\n",
    "    df['nij_t'] = np.ceil(df['nij_t'] / 60)\n",
    "\n",
    "    # Plot ECDF for temporal weight\n",
    "    plot_ecdf_for_classes(\n",
    "        df=df,\n",
    "        variable='nij_t',\n",
    "        save_path=f'figs/{target_date}-time.pdf',\n",
    "        x_axis_label='Avg. retweet time (minutes)',\n",
    "        log_x_axis=True\n",
    "    )\n",
    "\n",
    "    # Plot ECDF for retweet count weight\n",
    "    plot_ecdf_for_classes(\n",
    "        df=df,\n",
    "        variable='nij_c',\n",
    "        save_path=f'figs/{target_date}-count.pdf',\n",
    "        x_axis_label='# shared retweets',\n",
    "        log_x_axis=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2902e-6698-441e-97be-4b0625197886",
   "metadata": {},
   "source": [
    "## Edge Class Diversity per User\n",
    "\n",
    "This section shows the **distribution of users** according to the **number of distinct edge classes** they are connected to in the backbone network.\n",
    "\n",
    "Each bar represents the **fraction of users** who participate in 1, 2, 3, or 4 structurally distinct types of edges (as defined by count/time-based significance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a5aac-5389-4cba-b5d1-cf2109d0d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# List of target experiment dates\n",
    "target_dates = ['2022-11-01', '2023-01-08']\n",
    "\n",
    "# Maximum Y-axis fraction to display\n",
    "ylim_fraction = 0.8\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs('figs', exist_ok=True)\n",
    "\n",
    "for date in target_dates:\n",
    "    file_path = f\"networks/Backbone-{date}.csv\"\n",
    "\n",
    "    try:\n",
    "        # Load classified backbone data\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Reshape to long format: each user-role (src/trg) with its edge class\n",
    "        edges_per_user = df.melt(id_vars='edge_class', value_vars=['src', 'trg'],\n",
    "                                 var_name='role', value_name='user')\n",
    "\n",
    "        # Count how many distinct edge classes each user is involved in\n",
    "        class_count_per_user = edges_per_user.groupby('user')['edge_class'].nunique().reset_index()\n",
    "\n",
    "        # Aggregate: fraction of users by number of distinct edge classes\n",
    "        user_distribution = class_count_per_user['edge_class'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "        # Plot the distribution\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        plt.bar(user_distribution.index, user_distribution.values, color='skyblue')\n",
    "\n",
    "        # Axis labels and styling\n",
    "        plt.xlabel('# Distinct Edge Classes')\n",
    "        plt.ylabel('Fraction of Users')\n",
    "        plt.xticks(range(1, len(user_distribution) + 1))\n",
    "        plt.ylim(0, ylim_fraction)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        output_path = f\"figs/{date}_User_EdgeClass_Distribution.pdf\"\n",
    "        plt.savefig(output_path)\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
