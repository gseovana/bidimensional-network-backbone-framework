{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76525f-6525-482a-a6e6-8c1a645fdabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                         \n",
    "import numpy as np                          \n",
    "from tqdm.notebook import tqdm              \n",
    "from itertools import combinations          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc6cec2-8ab9-43eb-a1b1-17c07e36e1c2",
   "metadata": {},
   "source": [
    "## Tweet IDs and Twitter/X Policy\n",
    "\n",
    "According to Twitter/X's Developer Policy, direct sharing of tweet content (such as full text, user data, or media) is not permitted. Instead, researchers and developers are encouraged to share only **tweet IDs**, which can be used to retrieve the original tweet data via the official Twitter API—a process known as **hydration**.\n",
    "\n",
    "All tweet IDs used in this project are provided in the `Twitter/dataset` folder. These files contain only tweet identifiers, in compliance with Twitter/X's data sharing policy.\n",
    "\n",
    "### How to Reconstruct the Network\n",
    "\n",
    "To reconstruct the original tweet data and network:\n",
    "\n",
    "1. **Hydrate the tweet IDs** using a tool such as:\n",
    "   - [twarc](https://github.com/DocNow/twarc)\n",
    "   - [Hydrator](https://github.com/DocNow/hydrator)\n",
    "   - Or any custom script using the [Twitter API](https://developer.twitter.com/en/docs)\n",
    "\n",
    "2. **Collect the full tweet objects** by querying the IDs listed in the CSV files.\n",
    "\n",
    "3. **Rebuild the network** using the hydrated tweets and the provided edge definitions.\n",
    "\n",
    "> ⚠️ Please note: The success of hydration depends on the availability of the tweets. Tweets that have been deleted, protected, or otherwise made unavailable will not be retrievable.\n",
    "\n",
    "By following this approach, we ensure ethical data sharing and full compliance with Twitter/X’s terms of use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f0b75-a635-43d1-9f53-d448c3654678",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 🔁 Retweet Co-Engagement Network Construction\n",
    "\n",
    "This script processes a dataset of tweets to build **retweet co-engagement networks** for specific target dates.\n",
    "\n",
    "Each network captures **user-to-user edges** based on co-retweeting behavior:  \n",
    "If two users retweeted the **same original tweet** on the same day, they are connected in the network.\n",
    "\n",
    "### 🔧 Key Steps:\n",
    "1. **Load tweet data** with selected columns only.\n",
    "2. **Construct edges** between user pairs who retweeted the same tweet:\n",
    "   - `weight_count`: number of shared retweets.\n",
    "   - `weight_time`: average time difference (in seconds) between their retweet timestamps.\n",
    "3. **Export** the edge list as a `.csv` for further network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c82a54-3ef9-4649-a1c5-34c0691ba2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter environments\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load and prepare tweet dataset\n",
    "# ----------------------------------------\n",
    "\n",
    "# List only the necessary columns for loading\n",
    "required_columns = [\n",
    "    'id', 'conversation_id', 'referenced_tweets.replied_to.id', 'referenced_tweets.retweeted.id',\n",
    "    'referenced_tweets.quoted.id', 'author_id', 'in_reply_to_user_id', 'retweeted_user_id',\n",
    "    'quoted_user_id', 'created_at', 'text', 'entities.hashtags', 'entities.mentions',\n",
    "    'author.id', 'author.created_at', 'author.verified',\n",
    "    'public_metrics.retweet_count', 'public_metrics.like_count', 'public_metrics.quote_count',\n",
    "    'public_metrics.reply_count', 'public_metrics.impression_count'\n",
    "]\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('dataset/complete_data.csv', usecols=required_columns)\n",
    "\n",
    "# Convert the timestamp column to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing datetime or retweet reference\n",
    "df = df[df['created_at'].notnull()]\n",
    "df = df[df['referenced_tweets.retweeted.id'].notnull()]\n",
    "\n",
    "# Keep only necessary columns for network construction\n",
    "df = df[['id', 'author_id', 'created_at', 'referenced_tweets.retweeted.id']]\n",
    "df = df.rename(columns={'referenced_tweets.retweeted.id': 'retweeted_tweet_id'})\n",
    "\n",
    "# Add a simplified date column (date only, no time)\n",
    "df['date'] = df['created_at'].dt.date\n",
    "\n",
    "# ----------------------------------------\n",
    "# Set analysis parameters\n",
    "# ----------------------------------------\n",
    "\n",
    "# Dates for which we want to build the networks\n",
    "target_dates = ['2022-11-01', '2023-01-08']\n",
    "target_dates = [pd.to_datetime(date).date() for date in target_dates]\n",
    "\n",
    "# Loop over each target date to build a retweet co-engagement network\n",
    "for target_date in target_dates:\n",
    "    print(f\"Processing date: {target_date}\")\n",
    "\n",
    "    # Filter tweets from the target date only (no temporal windowing applied)\n",
    "    df_filtered = df[df['date'] == target_date]\n",
    "\n",
    "    # Filter out authors with fewer than 3 retweets (hardcoded threshold)\n",
    "\n",
    "    # Build the co-retweet network:\n",
    "    # Nodes = users\n",
    "    # Edges = co-retweeting the same original tweet\n",
    "    # Edge weight = number of shared retweets\n",
    "    # Edge time = average time difference in seconds between the retweets\n",
    "\n",
    "    # Set of all retweeted tweet IDs for this date\n",
    "    retweeted_ids = set(df_filtered['retweeted_tweet_id'])\n",
    "\n",
    "    # Dictionaries to accumulate weights and temporal distances\n",
    "    edge_weights = {}\n",
    "    edge_time_differences = {}\n",
    "\n",
    "    # For each original tweet that was retweeted:\n",
    "    for original_tweet_id in tqdm(retweeted_ids, desc=\"Building edges\"):\n",
    "        # Select all retweets of this tweet on the current date\n",
    "        sub_df = df_filtered[df_filtered['retweeted_tweet_id'] == original_tweet_id]\n",
    "\n",
    "        # Build a map of user_id -> retweet timestamp\n",
    "        user_time_map = dict(zip(sub_df['author_id'], sub_df['created_at']))\n",
    "\n",
    "        # Create all unique user pairs who retweeted the same tweet\n",
    "        for user_pair in combinations(sorted(user_time_map.keys()), 2):\n",
    "            time_diff = abs((user_time_map[user_pair[0]] - user_time_map[user_pair[1]]).total_seconds())\n",
    "\n",
    "            # Store time difference and update edge weight\n",
    "            edge_time_differences.setdefault(user_pair, []).append(time_diff)\n",
    "            edge_weights[user_pair] = edge_weights.get(user_pair, 0) + 1\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Export the edge list\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # Create DataFrame with: source, target, weight, average time diff\n",
    "    edge_list = [\n",
    "        (*pair, weight, np.mean(edge_time_differences[pair]))\n",
    "        for pair, weight in edge_weights.items()\n",
    "    ]\n",
    "\n",
    "    edge_df = pd.DataFrame(edge_list, columns=['src', 'trg', 'weight_count', 'weight_time'])\n",
    "\n",
    "    # Save edge list to CSV\n",
    "    output_path = f\"networks/{target_date}-edges-data.csv\"\n",
    "    edge_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Saved edge list to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062304b1-9881-48f4-92ab-bd13c9195ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-c.ferreira_ENV]",
   "language": "python",
   "name": "conda-env-.conda-c.ferreira_ENV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
